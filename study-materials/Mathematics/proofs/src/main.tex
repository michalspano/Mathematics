\documentclass[10pt,a4paper]{article}

% Packages
\usepackage[utf8]{inputenc}
\usepackage{amssymb}
\usepackage{mathtools}
\usepackage{gensymb}
\usepackage{amsmath}
\usepackage{MnSymbol}
\usepackage{pgfplots}
\usepackage{lineno}

\title{\textbf{Mathematical proofs}}
\author{Michal Spano}
\date{March 2022 - \textit{present}}

\begin{document}

\maketitle

\section*{The inner angle of an \textit{n-sided} convex regular polygon}

% Introduction
Suppose an $n-sided$ convex regular polygon. Its 4 consecutive vertices are shown in the figures, $N_1, N_2, N_3, ..., N_i$ respectively.
Thus $\Delta_{N_1,N_2,S} \cong \Delta_{N_2,N_3,S}$, i.e. such $n-sided$ polygon consists of $n$ congruent isosceles triangles.
That is, $|\measuredangle N_2 N_1 S| = |\measuredangle N_1 N_2 S| \Rightarrow |\measuredangle N_1 N_2 S| = |\measuredangle S N_2 N_3|$,
denoted as $\beta, \beta'$ respectively.

% Section I
An angle $\alpha = |\measuredangle N_1 S N_2| = \cfrac{360}{n}$, since such an angle multiplied by $n$ makes for a perfect circle of $360\degree$. 
Likewise $\alpha = 180\degree - 2 \beta$.

% Section II
Let $\phi$ be an inner angle of the polygon, such that $\phi = 2 \beta$ (shown in the figure at the vertex $N_2$).

% Steps of the proof
Given $\alpha$, let us re-arrange the expression in terms of $\beta$:

$$\alpha = 180 - 2 \beta \iff \beta = \cfrac{-\alpha + 180}{2}$$

Knowing the properties of $\alpha$, we substitute $\alpha$ for $\alpha = {360}/n$ and obtain:

$$\beta = \cfrac{-\cfrac{360}{n} + 180}{2} \iff \beta = \cfrac{180n - 360}{2n}$$

Knowing the definition of the inner angle of the polygon, namely $\phi = 2 \beta$, we have that:
$$\phi = 2 \beta = 2 \ast \Bigg( \cfrac{180n - 360}{2n} \Bigg) = \cfrac{180n - 360}{n}$$

The obtained expression can be further simplified to the following:

% End of the proof
$$\phi = \cfrac{(n-2) \pi}{n}$$

$\therefore$ the inner angle of an \textit{n-sided} convex regular polygon is ${(n-2) \ast \pi}n^{-1}$. $\blacksquare$

% Include a picture of a unit circle
\begin{figure}[htp]
    \centering
    \includegraphics[width=3.cm]{polygon_export.png}
    \caption{\textit{n-sided} polygon with its 4 vertices in a plane}
\end{figure}

\newpage

\section*{The number of diagonals of an $n-sided$ convex regular polygon}

Suppose a geometrical locus of $n$ points on the plane, 
% Steps of the proof
i.e. a set of points $A_1, A_2, ..., A_n$ 
such that $A_1, A_2, ..., A_n$ create an $n-sided$ convex regular polygon.
The number of different abscissas in the geometrical locus is ${n \choose 2}$ 
and denoted as $N_a$. It implies that no abscissa in the locus is given by more than two points, 
i.e. each point is unique. Likewise, $\overlinesegment{A_1A_2} \equiv \overlinesegment{A_2A_1}$ 
holds for any 2 points in the locus, thus such abscissas are counted as one. It can be inferred 
that the number of diagonals, denoted as $N_D$, is the same as \textit{the difference of the number of 
abscissas and the number of sides}: 

% End of the proof
$$N_D = N_s - n$$

\section*{The similarity coefficient}

% Start of the proof
Suppose a scalene triangle $\Delta_{ABC}$. We assume that there exists a triangle $\Delta_{A'B'C'}$,
such that $\Delta_{ABC} \cong \Delta_{A'B'C'}$. It implies that there exists some constant $c$,
such that any abscissa created in the locus of points (from the original triangle) is equal to the
product of $c$ and the corresponding abscissa of the similar triangle. Symbolically: 

% General expression
$\exists! c \in \mathbb{Q}: |V_1 V_2| = c \times |V_1' V_2'| \land c \gneqq 1$, where $V_1, V_2$ 
are the vertices of the original triangle.

% Section 1 - perimeters
Then, it can be easily inferred, that for the \textbf{perimeters} of the triangles
holds the following: Let $P = \overlinesegment{AB} + \overlinesegment{BC} + \overlinesegment{AC}$, similarly 
$P' = \overlinesegment{A'B'} + \overlinesegment{B'C'} + \overlinesegment{A'C'}$. Likewise
% Enumerating the similar sides with a constant
$
\overlinesegment{AB} = c \times \overlinesegment{A'B'} \land 
\overlinesegment{BC} = c \times \overlinesegment{B'C'} \land
\overlinesegment{AC} = c \times \overlinesegment{A'C'}
$. \\

% Steps of computation - perimeter
$P = c \times \overlinesegment{A'B'} + c \times \overlinesegment{B'C'} + c 
\times \overlinesegment{A'C'} \Rightarrow$
$P = c \times \Big( \overlinesegment{A'B'} + \overlinesegment{B'C'} + \overlinesegment{A'C'} \Big) = c \times P'$

$$\therefore P = c \times P'$$

% Conclusion of section 1
It implies that the ratio of the lengths of the sides of the similar triangles,
i.e. the ratio of their perimeters, is equal to the similarity coefficient:
$c = {P}/{P'}$.

% Section 2 - areas
Similar methodology is applied to the similarity coefficient of the areas of the triangles:

% Steps of computation - area
Let $A = \dfrac{\overlinesegment{AB} \times \overlinesegment{H_{AB}}}{2} \land 
A' = \dfrac{\overlinesegment{A'B'} \times \overlinesegment{H'_{AB}}}{2}$,
where $H_{AB}$ and $H'_{AB}$ are the heights of the triangles. Thus,
$A = \dfrac{c \times \overlinesegment{A'B'} c \times \overlinesegment{H'_{AB}}}{2} = 
c^2 \times \Bigg( \dfrac{\overlinesegment{A'B'} 
\times \overlinesegment{H'_{AB}}}{2} \Bigg) = c^2 \times A'$

$$\therefore A = c^2 \times A^{\prime}$$

% Conclusion of section 2
It implies, that the ratio of the areas equals to the similarity coefficient
taken to the second power: $c^2 = {A}/{A^{\prime}}$.

% Conclusion
To sum up, such a methodology is also applicable to derive the similarity coefficient 
of the volume of the tetrahedron. Moreover, it is also applicable to derive the similarity coefficient
of any planar polygon or solid figure (a scalene triangle per the given example is just an exemplary instance). 
Still, the following holds: $P = c \times P' \land A = c^2 \times A' \land V = c^3 \times V'$ 
based on the principles of \textbf{congruence}.

% End of the proof

\section*{Function bounded above and/or below}

% Start of the proof - bounded above and/or below function

Suppose a function $f$ which has a finite domain, say $D_f$. A function is bounded above if:
$\exists! a \in \mathbb{R}, \forall x \in D_f \subset \mathbb{R}: f(x) \leq a$. That is to say,
that every function value is smaller or equal to some constant, say $a$. Similarly, a function
is bounded below if: $\exists! b \in \mathbb{R}, \forall x \in D_f \subset \mathbb{R}: f(x) 
\geq b$. That implies, that every function value is greater or equal to some constant, say $b$.
Lastly, a function is bounded if both of the previous statements hold, i.e.:
$\exists! a \in \mathbb{R}, \exists! b \in \mathbb{R}, \forall x \in D_f \subset \mathbb{R}:
f(x) \leq a \land f(x) \geq b$. Hence, some bounded function $f$ has the following range of 
values: $[b;a]$, where $\{a,b\} \in \mathbb{R}$. For example, the function $f(x) = sin(x)$ 
is bounded, such that $[-1;1]$ is its range of values. \\

% Sample sin(x) plot
\begin{figure}[htp]
    \begin{center}  % Center the image
        \begin{tikzpicture}
            \begin{axis}[domain=0:2*pi,samples=100,smooth,xlabel={$x$},ylabel={$f(x)$}]
                \addplot[color=blue] {sin(deg(x))};  % sine function
                \addplot[color=black] {0};  % vertical line y = 0
            \end{axis}
        \end{tikzpicture}
    \end{center}

    % Caption the figure
    \caption{$sin(x)$, where $x \in [0;2 \pi]$}
\end{figure}

% End of the proof

\newpage

\section*{The standard rules of logarithms}

% Start of the proof - standard rules of logarithms

The following rules of logarithms hold for $x,y,a,s$, such that:

% Variable enumeration
\[\forall x,y \in\mathbb{R^+}, \forall a > 0 \land a \neq 1, \forall s \in\mathbb{R}\]

\begin{enumerate}
    \item{$\boldsymbol{\log_a 1 = 0}$}  % Rule number 1

    For any $a$ holds the following $a^0 = 1$. Therefore $log_a 1 = 0$.
    
    \item{$\boldsymbol{\log_a a = 1}$}  % Rule number 2

    For any $a$ holds the following $a^1 = a$. Therefore $log_a a = 1$.

    \item{$\boldsymbol{a^{\log_a x} = x}$}  % Rule number 3

    Let $l = \log_a x$. Therefore $a^{l} = x$. Combining the two rules, we obtain the following:
    $a^{\log_a x} = x$.

    \item{$\boldsymbol{\log_a (x \times y) = \log_a x + \log_a y}$}  % Rule number 4
    
    Suppose some $x,y$, where $x = a^{\log_a x}$, $y = a^{\log_a y}$. If we compute the product
    of them, we obtain that $x \times y = a^{\log_a x} \times a^{\log_a y}$. Furthermore, we 
    have that $a^{\log_a x + \log_a y} = x \times y$. According to the previous rule, we 
    obtain that $\log_a (x \times y) = \log_a x + \log_a y$.

    \item{$\boldsymbol{\log_a \Big( \frac{x}{y} \Big) = \log_a x - \log_a y}$}  % Rule number 5
    
    Similarly, suppose some $x,y$, where $x = a^{\log_a x}$, $y = a^{\log_a y}$. If we compute 
    the quotient of them, we obtain that $\cfrac{x}{y} = \cfrac{a^{\log_a x}}{a^{\log_a y}}$. 
    Furthermore,  we obtain that $a^{\log_a x - \log_a y} = \cfrac{x}{y}$. According to the third 
    rule, we have that $\log_a \big(\frac{x}{y}\big) = \log_a x - \log_a y$.

    \item{$\boldsymbol{\log_a x^{s} = s \times \log_a x}$}  % Rule number 6

    Suppose some $x$, where $x = a^{\log_a x}$. Power both sides of the equation by $s$, we 
    obtain that $x^{s} = (a^{\log_a x})^{s}$. Therefore $a^{s \times \log_a x} = x^{s}$.
    Having applied the third rule, it can be inferred that $\log_a x^{s} = s \times \log_a x$.

    \item{$\boldsymbol{\log_a x = \dfrac{\log_b x}{\log_b a}}$}  % Rule number 7

    Suppose some $x$, where $x = a^{\log_a x}$. Then, for some $\log$ with the base $b$ and the 
    argument $x$ holds $\log_b x = \log_b a^{\log_a x}$. Applying the sixth rule, we obtain that
    $\log_b x = \log_b a \times \log_a x$. Divide the equation by $\log_b a$, thus obtaining
    $\log_a x = \cfrac{\log_b x}{\log_b a}$.

\end{enumerate}
    
% End of the pr

\newpage

% Start of the proof - sum of n terms of an arithmetic sequence
\section*{The sum of $n$ terms of an arithmetic sequence}

Suppose an arithmetic sequence (also called a progression or a series) $\{a_{n}\}_{n=1}^{\infty}$. That is, a sequence of $n$ terms, where:
$$\exists! d \in \mathbb{R} - \{0\}, \forall i,j \in \mathbb{N}: d = a_{i} - a_{j} \land i - j = 1$$ 

That implies, that there exists exactly one constant, say $d$, such that the difference between every 2
consecutive terms is $d$. We label the sum of the first $n$ terms of the sequence as $S_{n}=\sum_{i=1}^n a_{i}$.
More explicitly, we have $S_{n} = a_{1} + a_{2} + \dots + a_{n-1} + a_{n}$. Similarly, if we reverse the 
sequence, we obtain $S_{n} = a_{n} + a_{n-1} + \dots + a_{2} + a_{1}$. Add the two sums, we obtain:

$$2 \times S_{n} = (a_{1} + a_{n}) + (a_{2} + a_{n-1}) + \dots + (a_{n-1} + a_{2}) + (a_{n} + a_{1})$$

Observe the similarity between the sums. E. g.
$(1 + 4) + (2 + 3) + \dots + (n + k) = (k + n) + \dots + (3 + 2) + (4 + 1)$
Thus, it can be inferred that $2 \times S_{n} = n \times (a_{n} + a_{1})$.
Lastly, we have that: $$S_{n} = \cfrac{n \times (a_{n} + a_{1})}{2}$$

\textbf{Conclusion:} The sum of $n$ terms of an arithmetic sequence is $\dfrac{n}{2} (a_{n} + a_{1})$.

% End of the proof

% Start of the proof - sum of n terms of an arithmetic sequence by mathematical induction

\section*{The sum of $n$ terms of an arithmetic sequence (proof)}

Suppose you are given a simple arithmetic sequence, where the difference between every 2 consecutive terms 
$d$ is 1. We assume the following (using the notation from the previous section): 
$$S_{n} = 1 + 2 + \dots + (n - 1) + n = \sum_{i=1}^{n} i = \frac{n}{2} (n + 1)$$

Formulate a statement, say $S(n)$, which is to be proven.

$$S(n): \forall n \in \mathbb{N}: 1 + 2 + \dots + n = \frac{n}{2} (n + 1)$$

First and foremost, we let $n=1$: $S(1): 1 = \frac{1}{2} (1 + 1)$. That is true. \linebreak  % Step 1
Secondly, assume that $S(k)$ holds for some arbitrary $k \in \mathbb{N}$.  % Step 2
That is our \textbf{induction hypothesis} (also called the induction assumption). We obtain:
$$S(k): 1 + 2 + \dots + k = \frac{k}{2} (k + 1)$$

Thirdly, $S(k) \implies S(k^{+})$, so we let $n=k+1$. Steps of the proof:  % Step 3

$$S(k + 1): 1 + 2 + \dots + k + (k + 1) = \cfrac{(k+1)(k+2)}{2}$$  % Steps of the proof
$$S(k + 1): S(k) + (k + 1) = \cfrac{(k+1)(k+2)}{2}$$
$$S(k + 1): \frac{k}{2} (k + 1) + (k + 1) = \cfrac{(k+1)(k+2)}{2}$$
$$S(k + 1): \cfrac{k(k+1) + 2(k+1)}{2} = \cfrac{(k+1)(k+2)}{2}$$
$$S(k + 1): \cfrac{(k+1)(k+2)}{2} = \cfrac{(k+1)(k+2)}{2}$$

We obtain that $S(k+1)$ holds and so must $S(k)$ (our induction hypothesis). That suffices to prove $S(n)$.
Finally, we have that $S(n)$ holds for all $n \in \mathbb{N}$, and thus \textbf{the proof is complete}. $\blacksquare$ % Step 4

% End of the proof

\section*{Quantifiers in mathematical logic (1)} 

\textbf{Task 1.} Show that $\neg \forall x [P(x)] \iff \exists [\neg P(x)]$.

\textbf{Solution}: Let's write the definition of the universal quantifier, where $A$ is a set of some $n$ finite elements,
namely, $\{a_{1}, a_{2}, \dots, a_{n}\}$: $\neg \forall x \in A: P(x) \iff \neg \big( P(a_{1}) \land P(a_{2}) \land \dots \land P(a_{n}) \big)$.
If we apply the the De Morgan's law, we obtain $\neg \forall x \in A: P(x) \iff \neg P(a_{1}) \lor \neg P(a_{2}) \lor \dots \lor \neg P(a_{n})$.
This simply states, that there's at least one element in the set $A$ for which the statement $P(x)$ is false. 
We may factor the negation sign out of the sequence of predicates, thus obtaining $\neg \forall x \in A: P(x) \iff \neg \big( P(a_{1}) \lor P(a_{2}) \lor \dots \lor P(a_{n}) \big)$. 
Were we to apply the definition of the existential quantifier, we receive that $\neg \forall x \in A: P(x) \iff \exists x \in A: \neg P(x)$,
since $\exists x \in A: P(a_{1}) \lor P(a_{2}) \lor \dots \lor P(a_{n})$ which completes the proof - we've shown that the two mathematical expressions are equivalent. $\blacksquare$

\textbf{Note}: the same analogy is used to show the negation of the existential quantifier. For brevity,
it's left to the reader to prove it.

% End of the first proof of the quantifiers

\section*{Quantifiers in mathematical logic (2)}

\textbf{Task 2.} Negate the following expression: $\forall x \exists y [P(x, y) \land Q(x)]$.

\textbf{Solution}: the resulting expression is broken down into 4 consecutive steps. A brief description is
adduced for each step. Observe the steps one by one until the resulting expression:

\begin{linenomath*}
    \begin{equation}
        \neg \big( \forall x \exists y [P(x, y) \land Q(x)] \big)
        \text{ - the initial expression is negated}
    \end{equation} 
    \begin{equation}
        \exists x \neg \big( \exists y [P(x, y) \land Q(x)] \big)
        \text{ - the outer quantifier is negated}
    \end{equation}
    \begin{equation}
        \exists x \forall y \neg \big( [P(x, y) \land Q(x)] \big)
        \text{ - the inner quantifier is negated}
    \end{equation}
    \begin{equation}
        \exists x \forall y [\neg P(x, y) \lor \neg Q(x)]
        \text{ - De Morgan's law} ^{\ast} \text{ is applied}
    \end{equation}
    \begin{equation}
        \text{The resulting expression. } \blacksquare
    \end{equation}
    
\end{linenomath*}

$^{\ast}$In this case, it represents the negation of the conjunction, 
namely: $\neg \big( A(x) \land B(x) \big) \equiv \neg A(x) \lor \neg B(x)$ 
for some predicates $A$ and $B$ given $x$.

\end{document}

% End of the second proof of the quantifiers
